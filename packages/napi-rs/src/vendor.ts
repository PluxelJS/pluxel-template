import fs from 'node:fs'
import { mkdir, readFile, writeFile } from 'node:fs/promises'
import path from 'node:path'
import { createGzipDecoder, createTarDecoder } from 'modern-tar'

import {
	PACKAGE_ROOT,
	defaultManifestPath,
	mergeManifest,
	readManifest,
	type ManifestEntry,
	type ManifestFile,
	type VendorTarget,
	writeManifest,
} from './manifest'

const SKIP_CORE_BASENAMES = new Set(['js-binding.js', 'js-bindings.js'])
const DEFAULT_REGISTRY =
	process.env.NPM_REGISTRY || process.env.NAPI_RS_REGISTRY || 'https://registry.npmjs.org'

interface TarEntry {
	header: { name?: string }
	body?: ReadableStream<Uint8Array> | null
}

export interface VendorOptions {
	registry?: string
	cwd?: string
	updateExports?: boolean
	logger?: Pick<Console, 'log' | 'warn'>
}

export interface VendorResult {
	name: string
	requestedVersion?: string | null
	resolvedVersion: string
	tarballUrl: string
	outDir: string
	bindingPath: string
}

export function sanitizeForPath(name: string): string {
	return name.replace(/^@/, '').replace(/[\/\\]/g, '__')
}

function deriveExportKey(pkgName: string): string {
	const seg = pkgName.split('/').pop() || pkgName
	return seg.replace(/^@/, '')
}

export function formatOutDirForManifest(outDir: string, cwd: string): string {
	const rel = path.relative(cwd, outDir)
	if (!rel || rel === '.') return '.'
	if (rel.startsWith('..')) return outDir
	return rel.startsWith('./') ? rel : `./${rel}`
}

async function fetchJson(url: string): Promise<unknown> {
	const res = await fetch(url)
	if (!res.ok) {
		throw new Error(`Failed to fetch ${url}: ${res.status} ${res.statusText}`)
	}
	return res.json()
}

async function resolveTarballUrl(pkgName: string, version: string | null, registry: string) {
	const metaUrl = `${registry}/${encodeURIComponent(pkgName)}`
	const json = (await fetchJson(metaUrl)) as Record<string, any>

	const resolvedVersion =
		version ??
		json['dist-tags']?.latest ??
		(() => {
			throw new Error(`Cannot resolve version for ${pkgName}`)
		})()

	const pkgMeta = json.versions?.[resolvedVersion]
	const tarballUrl = pkgMeta?.dist?.tarball

	if (!tarballUrl) {
		throw new Error(`No dist.tarball found for ${pkgName}@${resolvedVersion}`)
	}

	return { version: resolvedVersion, tarballUrl }
}

async function downloadEntries(tarballUrl: string) {
	const res = await fetch(tarballUrl)
	if (!res.ok || !res.body) {
		throw new Error(`Failed to fetch tarball: ${res.status} ${res.statusText}`)
	}

	return res.body.pipeThrough(createGzipDecoder()).pipeThrough(createTarDecoder())
}

async function writeCoreEntry(
	rootDir: string,
	header: TarEntry['header'],
	bodyStream?: ReadableStream<Uint8Array> | null,
) {
	let name = header.name || ''

	if (name.startsWith('package/')) {
		name = name.slice('package/'.length)
	}

	if (!name || name.endsWith('/')) {
		return
	}

	const base = path.basename(name)
	if (SKIP_CORE_BASENAMES.has(base)) {
		await bodyStream?.cancel?.().catch(() => {})
		return
	}

	const destPath = path.join(rootDir, name)
	await mkdir(path.dirname(destPath), { recursive: true })

	if (!bodyStream) return

	const reader = bodyStream.getReader()
	const writer = fs.createWriteStream(destPath)

	try {
		while (true) {
			const { done, value } = await reader.read()
			if (done) break
			if (!value) continue

			if (!writer.write(Buffer.from(value))) {
				await new Promise((resolve) => writer.once('drain', resolve))
			}
		}
	} finally {
		writer.end()
	}
}

async function patchIndexNativeBinding(outDir: string) {
	const indexPath = path.join(outDir, 'index.js')
	let code: string
	try {
		code = await readFile(indexPath, 'utf8')
	} catch {
		return
	}

	// Already patched
	if (code.includes('require("./js-binding.js")') || code.includes("require('./js-binding.js')")) {
		return
	}

	let replaced = false

	const replacePatterns: Array<[RegExp, (match: string, kw?: string) => string]> = [
		[/nativeBinding\s*=\s*requireNative\(\)/g, () => 'nativeBinding = require("./js-binding.js")'],
		[/nativeBinding\s*=\s*requireNative\(\);/g, () => 'nativeBinding = require("./js-binding.js");'],
		[
			/(const|let|var)\s+nativeBinding\s*=\s*requireNative\(\)/,
			(_, kw) => `${kw} nativeBinding = require("./js-binding.js")`,
		],
	]

	for (const [pattern, replacer] of replacePatterns) {
		if (pattern.test(code)) {
			code = code.replace(pattern, replacer as any)
			replaced = true
		}
	}

	if (!replaced) return

	await writeFile(indexPath, code, 'utf8')
}

// This stays as a string template to keep the generated js-binding.js lean.
export function renderGeneratedBindingJs(): string {
	return `
// Auto-generated by pluxel-plugin-napi-rs
//
// Universal CJS js-binding for napi-rs style packages.
//
// Reads from ./package.json:
//   - napi.binaryName
//   - optionalDependencies
//
// Stores runtime binaries at:
//   <process.cwd()>/napi-rs/<binaryName>/*.node
//
// Env:
//   - NAPI_RS_DISABLE_RUNTIME_DOWNLOAD=1
//   - NAPI_RS_REGISTRY / NPM_REGISTRY

const fs = require("node:fs");
const path = require("node:path");
const { spawnSync } = require("node:child_process");
const pkgRoot = path.resolve(__dirname, "..");

const corePkg = require("./package.json");
const binaryName = corePkg && corePkg.napi && corePkg.napi.binaryName;

if (!binaryName) {
  throw new Error("Missing napi.binaryName in core package.json");
}

const optional = corePkg.optionalDependencies || {};
const optionalNames = Object.keys(optional);

const NAPI_ROOT = path.join(process.cwd(), "napi-rs");
const BIN_DIR = path.join(NAPI_ROOT, binaryName);

function detectMusl() {
  if (process.platform !== "linux") return false;
  try {
    const report = process.report && process.report.getReport && process.report.getReport();
    return !(report && report.header && report.header.glibcVersionRuntime);
  } catch (_) {
    return false;
  }
}

/**
 * Strict white-list selection:
 *  - optionalDependencies is the upstream whitelist
 *  - filter by platform + arch only
 *  - 0 candidates -> throw
 *  - linux: prefer musl/gnu if multiple candidates exist
 */
function pickBinaryPackageName() {
  const p = process.platform;
  const a = process.arch;

  const candidates = optionalNames.filter(
    (n) => n.indexOf("-" + p + "-") !== -1 && n.indexOf("-" + a + "-") !== -1,
  );

  if (candidates.length === 0) {
    throw new Error(
      "No prebuilt binary listed for " + p + "/" + a +
      ". Available optionalDependencies: " + optionalNames.join(", ")
    );
  }

  if (candidates.length === 1) return candidates[0];

  if (p === "linux") {
    const musl = detectMusl();
    const preferred = candidates.find((n) => n.indexOf(musl ? "musl" : "gnu") !== -1);
    if (preferred) return preferred;
  }

  return candidates.sort()[0];
}

function listLocalNodes(dir) {
  try {
    return fs.readdirSync(dir).filter(function (f) {
      return f.endsWith(".node");
    }).sort();
  } catch (_) {
    return [];
  }
}

function pickLocalNodeFile() {
  const nodes = listLocalNodes(BIN_DIR);
  if (nodes.length === 0) return null;
  return nodes[0];
}

function findBundledNodeFile() {
  try {
    const files = fs.readdirSync(pkgRoot).filter(function (f) {
      return f.endsWith(".node");
    }).sort();
    if (files.length === 0) return null;
    return path.join(pkgRoot, files[0]);
  } catch (_) {
    return null;
  }
}

/**
 * Sync download/extract:
 *  - parent process keeps require synchronous
 *  - child process runs ESM + modern-tar for async fetch + streaming extraction
 *  - child resolves dist.tarball from registry metadata (no URL guessing)
 */
function ensureBinaryDownloaded(depName, depVersion) {
  fs.mkdirSync(BIN_DIR, { recursive: true });

  const esmLines = [
    'import fs from "node:fs";',
    'import path from "node:path";',
    'import crypto from "node:crypto";',
    'import { createGzipDecoder, unpackTar } from "modern-tar";',
    '',
    'const depName = process.env.NAPI_RS_DEP_NAME;',
    'const depVersion = process.env.NAPI_RS_DEP_VERSION;',
    'const binaryName = process.env.NAPI_RS_BINARY_NAME;',
    'const outRoot = process.env.NAPI_RS_OUT_ROOT;',
    'const registry = process.env.NAPI_RS_REGISTRY || process.env.NPM_REGISTRY || "https://registry.npmjs.org";',
    '',
    'if (!depName || !depVersion || !binaryName || !outRoot) {',
    '  throw new Error("Missing env for runtime downloader");',
    '}',
    '',
    'function toHashPlan(integrity, shasum) {',
    '  if (integrity) {',
    '    const parts = integrity.split("-");',
    '    const algo = parts[0] || "sha512";',
    '    const expected = parts[1] || "";',
    '    return { algo, expected, format: "base64" };',
    '  }',
    '  if (shasum) {',
    '    return { algo: "sha1", expected: String(shasum).toLowerCase(), format: "hex" };',
    '  }',
    '  return null;',
    '}',
    '',
    'async function verifyIntegrity(body, integrity, shasum) {',
    '  const plan = toHashPlan(integrity, shasum);',
    '  if (!plan) return;',
    '  const hash = crypto.createHash(plan.algo);',
    '  const reader = body.getReader();',
    '  while (true) {',
    '    const { done, value } = await reader.read();',
    '    if (done) break;',
    '    if (value) hash.update(value);',
    '  }',
    '  const digest = hash.digest(plan.format);',
    '  const ok = plan.format === "hex"',
    '    ? digest.toLowerCase() === plan.expected',
    '    : digest === plan.expected;',
    '  if (!ok) {',
    '    throw new Error("Integrity check failed for " + depName + "@" + depVersion);',
    '  }',
    '}',
    '',
    'const metaUrl = registry + "/" + encodeURIComponent(depName);',
    'const metaRes = await fetch(metaUrl);',
    'if (!metaRes.ok) {',
    '  throw new Error("Failed to fetch metadata: " + metaUrl + " " + metaRes.status);',
    '}',
    'const meta = await metaRes.json();',
    'const verMeta = meta.versions && meta.versions[depVersion];',
    'const tarballUrl = verMeta && verMeta.dist && verMeta.dist.tarball;',
    'const integrity = verMeta && verMeta.dist && verMeta.dist.integrity;',
    'const shasum = verMeta && verMeta.dist && verMeta.dist.shasum;',
    'if (!tarballUrl) {',
    '  throw new Error("No dist.tarball for " + depName + "@" + depVersion);',
    '}',
    '',
    'const res = await fetch(tarballUrl);',
    'if (!res.ok || !res.body) {',
    '  throw new Error("Failed to fetch binary tarball: " + tarballUrl + " " + res.status);',
    '}',
    '',
    'const outDir = path.join(outRoot, binaryName);',
    'fs.mkdirSync(outDir, { recursive: true });',
    'const cleanupNodes = () => {',
    '  try {',
    '    for (const f of fs.readdirSync(outDir)) {',
    '      if (f.endsWith(".node")) {',
    '        fs.rmSync(path.join(outDir, f), { force: true });',
    '      }',
    '    }',
    '  } catch (_) {}',
    '};',
    'cleanupNodes();',
    '',
    'let extractBody = res.body;',
    'const needsIntegrity = integrity || shasum;',
    'if (needsIntegrity && res.body) {',
    '  if (res.body.tee) {',
    '    const [hashStream, extractStream] = res.body.tee();',
    '    await verifyIntegrity(hashStream, integrity, shasum);',
    '    extractBody = extractStream;',
    '  } else {',
    '    const chunks = [];',
    '    const reader = res.body.getReader();',
    '    while (true) {',
    '      const { done, value } = await reader.read();',
    '      if (done) break;',
    '      if (value) chunks.push(Buffer.from(value));',
    '    }',
    '    const full = Buffer.concat(chunks);',
    '    await verifyIntegrity(new Blob([full]).stream(), integrity, shasum);',
    '    extractBody = new Blob([full]).stream();',
    '  }',
    '}',
    '',
    'const entries = await unpackTar(',
    '  extractBody.pipeThrough(createGzipDecoder()),',
    ');',
    '',
    'let wroteAny = false;',
    'for (const entry of entries) {',
    '  let name = entry.header.name || "";',
    '  if (name.startsWith("package/")) name = name.slice("package/".length);',
    '  if (!name || name.endsWith("/")) {',
    '    continue;',
    '  }',
    '  const base = path.basename(name);',
    '  if (!base.endsWith(".node")) {',
    '    continue;',
    '  }',
    '  const data = entry && entry.data;',
    '  if (!data || data.length === 0) {',
    '    continue;',
    '  }',
    '  const dest = path.join(outDir, base);',
    '  fs.writeFileSync(dest, data);',
    '  wroteAny = true;',
    '}',
    '',
    'if (!wroteAny) {',
    '  cleanupNodes();',
    '  throw new Error("No .node extracted from " + depName + "@" + depVersion);',
    '}',
  ];

  const esm = esmLines.join("\\n");

  const child = spawnSync(
    process.execPath,
    ["--input-type=module", "-e", esm],
    {
      stdio: "inherit",
      // Run from package root so the bundled modern-tar dependency is resolvable
      cwd: pkgRoot,
      env: {
        ...process.env,
        NAPI_RS_DEP_NAME: depName,
        NAPI_RS_DEP_VERSION: depVersion,
        NAPI_RS_BINARY_NAME: binaryName,
        NAPI_RS_OUT_ROOT: NAPI_ROOT,
      },
    },
  );

  if (child.status !== 0) {
    throw new Error("Runtime download failed for " + depName + "@" + depVersion);
  }
}

function loadNative() {
  const bundled = findBundledNodeFile();
  if (bundled) {
    return require(bundled);
  }

  let local = pickLocalNodeFile();
  if (local) {
    return require(path.join(BIN_DIR, local));
  }

  const depName = pickBinaryPackageName();
  const depVersion = optional[depName];

  if (!depVersion) {
    throw new Error("Missing version for optional dependency: " + depName);
  }

  if (process.env.NAPI_RS_DISABLE_RUNTIME_DOWNLOAD === "1") {
    throw new Error(
      "Runtime download disabled and no local .node found at: " + BIN_DIR,
    );
  }

  ensureBinaryDownloaded(depName, depVersion);

  local = pickLocalNodeFile();
  if (!local) {
    throw new Error("No .node found after download at: " + BIN_DIR);
  }

  return require(path.join(BIN_DIR, local));
}

module.exports = loadNative();
`
}

export function renderGeneratedBindingEsmWrapper(exportNames: string[] = []): string {
	const names = Array.from(new Set(exportNames)).filter(Boolean)
	const exportLines =
		names.length === 0
			? ''
			: names
					.map((name) => `export const ${name} = exported["${name}"];`)
					.join('\n')

	return `
import binding from "./js-binding.cjs";

const exported = (binding && typeof binding === "object") ? binding : {};
export default binding;
${exportLines}
`
}

export async function updateExportsFromManifest(
	manifest: ManifestFile,
	options: { pkgJsonPath?: string; cwd?: string; enabled?: boolean } = {},
) {
	if (options.enabled === false) return

	const pkgJsonPath = options.pkgJsonPath || path.join(PACKAGE_ROOT, 'package.json')
	const cwd = options.cwd ? path.resolve(options.cwd) : PACKAGE_ROOT

	let pkgRaw: string
	try {
		pkgRaw = await readFile(pkgJsonPath, 'utf8')
	} catch (err: unknown) {
		console.warn(`[napi-rs] skip exports update (cannot read package.json): ${pkgJsonPath}`)
		console.warn(err)
		return
	}

	const pkgJson = JSON.parse(pkgRaw) as Record<string, any>
	const exportsField = (pkgJson.exports && typeof pkgJson.exports === 'object' && !Array.isArray(pkgJson.exports)
		? { ...pkgJson.exports }
		: {}) as Record<string, any>

	for (const entry of manifest.packages) {
		const alias = deriveExportKey(entry.name)
		const outDir = entry.outDir || sanitizeForPath(entry.name)
		const absOut = path.resolve(cwd, outDir)
		let relOut = path.relative(path.dirname(pkgJsonPath), absOut)
		if (!relOut.startsWith('.')) relOut = `./${relOut}`
		exportsField[`./${alias}`] = `${relOut}/index.js`
	}

	pkgJson.exports = exportsField
	await writeFile(pkgJsonPath, JSON.stringify(pkgJson, null, 2) + '\n', 'utf8')
}

export async function vendorPackage(target: VendorTarget, options: VendorOptions = {}): Promise<VendorResult> {
	const registry = options.registry || DEFAULT_REGISTRY
	const cwd = options.cwd ? path.resolve(options.cwd) : PACKAGE_ROOT
	const logger = options.logger ?? console
	const requestedVersion = target.version === 'latest' ? null : target.version

	const outDir = path.resolve(cwd, target.outDir || sanitizeForPath(target.name))
	logger.log?.(
		`[napi-rs] resolving ${target.name}@${requestedVersion || '(latest)'} -> ${outDir} (registry: ${registry})`,
	)

	const { version, tarballUrl } = await resolveTarballUrl(target.name, requestedVersion ?? null, registry)

	await mkdir(outDir, { recursive: true })

	const entries = await downloadEntries(tarballUrl)
	for await (const entry of entries as AsyncIterable<TarEntry>) {
		await writeCoreEntry(outDir, entry.header, entry.body)
	}

	const bindingPath = path.join(outDir, 'js-binding.js')
	let bindingIsEsm = false
	let esmImportNames: string[] = []
	const pkgJsonPath = path.join(outDir, 'package.json')
	try {
		const pkgJsonRaw = await readFile(pkgJsonPath, 'utf8')
		const pkgJson = JSON.parse(pkgJsonRaw) as Record<string, any>
		bindingIsEsm = pkgJson.type === 'module'
	} catch (err) {
		logger.warn?.(`[napi-rs] cannot read package.json to decide js-binding format: ${pkgJsonPath}`)
		logger.warn?.(err as any)
	}

	if (bindingIsEsm) {
		// Try to derive named imports from the package's index.js so the wrapper can re-export them.
		try {
			const indexRaw = await readFile(path.join(outDir, 'index.js'), 'utf8')
			const importMatch = indexRaw.match(/import\s*{\s*([^}]*)}\s*from\s*["']\.\/js-binding\.js["']/s)
			if (importMatch && importMatch[1]) {
				esmImportNames = importMatch[1]
					.split(',')
					.map((s) => s.trim())
					.filter(Boolean)
			}
		} catch (err) {
			logger.warn?.(`[napi-rs] cannot read index.js to derive named exports: ${path.join(outDir, 'index.js')}`)
			logger.warn?.(err as any)
		}

		const cjsBindingPath = path.join(outDir, 'js-binding.cjs')
		await writeFile(cjsBindingPath, renderGeneratedBindingJs(), 'utf8')
		await writeFile(bindingPath, renderGeneratedBindingEsmWrapper(esmImportNames), 'utf8')

		try {
			const pkgJsonRaw = await readFile(pkgJsonPath, 'utf8')
			const pkgJson = JSON.parse(pkgJsonRaw) as Record<string, any>
			if (Array.isArray(pkgJson.files) && !pkgJson.files.includes('js-binding.cjs')) {
				pkgJson.files.push('js-binding.cjs')
				await writeFile(pkgJsonPath, JSON.stringify(pkgJson, null, 2) + '\n', 'utf8')
			}
		} catch (err) {
			logger.warn?.(`[napi-rs] cannot update files[] to include js-binding.cjs: ${pkgJsonPath}`)
			logger.warn?.(err as any)
		}
	} else {
		await writeFile(bindingPath, renderGeneratedBindingJs(), 'utf8')
	}
	await patchIndexNativeBinding(outDir)

	logger.log?.(`[napi-rs] wrote ${target.name}@${version} to ${outDir}`)

	return {
		name: target.name,
			requestedVersion,
			resolvedVersion: version,
			tarballUrl,
			outDir,
			bindingPath,
		}
}

export async function vendorPackages(
	targets: VendorTarget[],
	options: VendorOptions = {},
): Promise<VendorResult[]> {
	const results: VendorResult[] = []
	for (const target of targets) {
		results.push(await vendorPackage(target, options))
	}
	return results
}

export interface VendorManifestResult {
	manifest: ManifestFile
	manifestPath: string
	results: VendorResult[]
}

export async function vendorFromManifest(
	manifestPath: string = defaultManifestPath(),
	options: VendorOptions = {},
): Promise<VendorManifestResult> {
	const cwd = options.cwd ? path.resolve(options.cwd) : PACKAGE_ROOT
	const resolvedManifestPath = path.resolve(cwd, manifestPath)
	const manifest = await readManifest(resolvedManifestPath)
	const registry = options.registry || manifest.registry || DEFAULT_REGISTRY
	const targets = manifest.packages as VendorTarget[]

	if (!targets.length) {
		throw new Error(
			'No packages listed in manifest. Provide --packages "<name@version ...>" or add entries to vendor.manifest.json',
		)
	}

	const results = await vendorPackages(targets, { ...options, registry, cwd })

	const manifestUpdates: ManifestEntry[] = results.map((res) => {
		const original = targets.find((pkg) => pkg.name === res.name)
		return {
			name: res.name,
			version: original?.version ?? res.requestedVersion ?? undefined,
			resolvedVersion: res.resolvedVersion,
			tarballUrl: res.tarballUrl,
			outDir: formatOutDirForManifest(res.outDir, cwd),
			updatedAt: new Date().toISOString(),
		}
	})

	const nextManifest = mergeManifest(manifest, manifestUpdates, registry)
	await writeManifest(resolvedManifestPath, nextManifest)
	await updateExportsFromManifest(nextManifest, {
		cwd,
		enabled: options.updateExports !== false,
	})

	return {
		manifest: nextManifest,
		manifestPath: resolvedManifestPath,
		results,
	}
}
